includes:
  - ./hateful_memes/defaults.yaml
  - ./visual_entailment/defaults.yaml
  - ./vqa2/train_val.yaml

model_config:
  moevilbert:
    training_head_type: classification
    freeze_base: true
    freeze_gating_encoders: true
    experts_count: 4
    classifiers:
      vqa2:
        num_labels: 3129
        losses:
        - type: logit_bce
      visual_entailment:
        num_labels: 3
        losses:
        - type: cross_entropy
      hateful_memes:
        num_labels: 2
        losses:
        - type: cross_entropy
    gating_image_encoder:
      type: resnet152
      params:
        pretrained: true
        pool_type: avg
        num_output_features: 1
    gating_text_encoder:
      type: transformer
      params:
        bert_model_name: bert-base-uncased
        hidden_size: 768
        num_hidden_layers: 12
        num_attention_heads: 12
        output_attentions: false
        output_hidden_states: false

optimizer:
  # allow_unused_parameters: true
  type: adam_w
  params:
    lr: 5e-5
    eps: 1e-8

scheduler:
  type: warmup_linear
  params:
    num_warmup_steps: 6000
    num_training_steps: 60000

evaluation:
  metrics:
  - type: vqa_accuracy
    datasets:
    - vqa2
  - type: accuracy
    key: accuracy
    datasets:
    - visual_entailment
    - hateful_memes

training:
  batch_size: 2
  lr_scheduler: true
  # Don't forget to update schedule_attributes if you update this
  max_updates: 60000
  find_unused_parameters: true
  early_stop:
    enabled: false
    criteria: vqa2/vqa_accuracy
    minimize: false

multitasking:
  enabled: true
  type: ratios
  params:
    sampling_ratios:
      vqa2: 0.4
      hateful_memes: 0.3
      visual_entailment: 0.3

checkpoint:
  pretrained_state_mapping:
    model.bert: model.bert